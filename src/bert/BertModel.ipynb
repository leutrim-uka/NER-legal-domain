{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Install and import necessary libraries and packages"
   ],
   "metadata": {
    "id": "Ka-aXpmuvA-o",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Instructions: connect to a GPU and click on run all. Provided that paths to CSV files are correct, everything should execute on its own. Scroll down to the bottom of the notebook for the results."
   ],
   "metadata": {
    "id": "XpdemIzcFwYQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import  DistilBertForTokenClassification, BertModel\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.metrics import accuracy_score,f1_score, precision_score, recall_score, classification_report"
   ],
   "metadata": {
    "id": "ldQNY4I-YJDX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "id": "3jT8U6rHG07s",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reading and preparing the data\n",
    "Read data in CSV format. The data file should contain the columns 'sentences' (or 'sentence') and 'tags'. The former should contain plain-text sentences (non-tokenized), and the latter should contain a list of IOB tags."
   ],
   "metadata": {
    "id": "VnJmh6lN0JmG",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NyyHxrK3X-G3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../../data/bert_train_iob.csv')\n",
    "test_df = pd.read_csv('../../data/bert_test_iob.csv')\n",
    "\n",
    "if 'Unnamed: 0' in train_df.columns:\n",
    "  train_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "if 'Unnamed: 0' in test_df.columns:\n",
    "  test_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "# Pandas reads lists as strings. Evaluate them into lists\n",
    "train_df['tags'] = train_df['tags'].apply(lambda x: eval(x))\n",
    "test_df['tags'] = test_df['tags'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# combine labels from training and testing set into a list\n",
    "unified_labels = []\n",
    "unified_labels.extend(train_df.tags.to_list())\n",
    "unified_labels.extend(test_df.tags.to_list())\n",
    "\n",
    "# extract all labels from the 'iob' column of the dataframe\n",
    "labels = [label for row in unified_labels for label in row]\n",
    "\n",
    "# create a list with unique labels from our data set\n",
    "label_list = list(set(labels))\n",
    "print(f\"List of unique labels: {label_list}\")\n",
    "\n",
    "# create dictionaries that map labels to numeric IDs and vice-versa\n",
    "labels_to_ids = {lbl: id for id, lbl in enumerate(sorted(label_list))}\n",
    "ids_to_labels = {id: lbl for id, lbl in enumerate(sorted(label_list))}\n",
    "\n",
    "# join tags back into a string after performing all operations that require a list format\n",
    "train_df['tags'] = train_df['tags'].apply(lambda x: ' '.join(x))\n",
    "test_df['tags'] = test_df['tags'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "train_df.rename(columns={'sentences': 'sentence'}, inplace=True)\n",
    "test_df.rename(columns={'sentences': 'sentence'}, inplace=True)\n",
    "\n",
    "# Generate validation data from 20% of the training data set\n",
    "df_train, df_val = np.split(train_df.sample(frac=1, random_state=42), [int(.8 * len(train_df))])\n",
    "df_test = test_df"
   ],
   "metadata": {
    "id": "6upklYwCvh_y",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "8965d5f9-ac0e-4ed6-a246-7d3a849ed330",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "List of unique labels: ['I-ORG', 'B-OTHER_PERSON', 'I-WITNESS', 'I-DATE', 'B-PROVISION', 'B-ORG', 'B-CASE_NUMBER', 'I-GPE', 'B-RESPONDENT', 'I-STATUTE', 'I-PRECEDENT', 'B-LAWYER', 'I-PETITIONER', 'B-WITNESS', 'I-LAWYER', 'B-JUDGE', 'O', 'I-JUDGE', 'B-COURT', 'B-PRECEDENT', 'I-CASE_NUMBER', 'B-PETITIONER', 'B-STATUTE', 'I-OTHER_PERSON', 'I-PROVISION', 'I-COURT', 'I-RESPONDENT', 'B-GPE', 'B-DATE']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# CustomDataset allows us to retrieve batches of variable lengths of the data for training and validating\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, df):\n",
    "    self.texts = []\n",
    "    self.labels = []\n",
    "    list_of_tags = []\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    for value in df['tags'].values.tolist():\n",
    "      splitted = value.split()\n",
    "      list_of_tags.append(splitted)\n",
    "    \n",
    "    texts = df[\"sentence\"].values.tolist()\n",
    "\n",
    "    for t in texts:\n",
    "      encoded_text = tokenizer(t, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "      self.texts.append(encoded_text)\n",
    "\n",
    "    for text, tags in zip(self.texts, list_of_tags):\n",
    "      word_ids = text.word_ids()\n",
    "      pwid = None\n",
    "      label_ids = []\n",
    "\n",
    "      for id in word_ids:\n",
    "        if id is None:\n",
    "            label_ids.append(-100)\n",
    "        else :\n",
    "            try:\n",
    "              ref = tags[id]\n",
    "              label_ids.append(labels_to_ids[ref])\n",
    "            except:\n",
    "              label_ids.append(-100)\n",
    "              \n",
    "            pwid = id\n",
    "\n",
    "      self.labels.append(label_ids)\n",
    "\n",
    "  # this method is not called directly but is referenced behind the scenes\n",
    "  # removing it throws an error\n",
    "  def __len__(self):\n",
    "    return len(self.labels)\n",
    "\n",
    "  def __getitem__(self, id):\n",
    "    txt = self.texts[id]\n",
    "    lbl = self.labels[id]\n",
    "\n",
    "    return txt, torch.LongTensor(lbl)"
   ],
   "metadata": {
    "id": "ieg9bxR2Yfbn",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Defining the DistilBERT model"
   ],
   "metadata": {
    "id": "VQJong7QyypM",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Bert(nn.Module):\n",
    " \n",
    "  def __init__(self, label_count):\n",
    "    super(Bert, self).__init__()\n",
    "    self.bert = DistilBertForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels = label_count)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask, labels = None):\n",
    "\n",
    "    # we need this because we don't provide the labels when we predict a sentence\n",
    "    if labels == None:\n",
    "      output = self.bert(input_ids = input_ids, attention_mask = attention_mask)\n",
    "      return output\n",
    "\n",
    "    # this is executed during training and testing, since labels are provided\n",
    "    output = self.bert(input_ids = input_ids, attention_mask = attention_mask , labels = labels)\n",
    "    return output\n",
    "\n",
    "  def fit(self, train_dataset, dev_dataset, optimizer,  batch_size, epochs):\n",
    "\n",
    "    self.results = {\n",
    "      'train': {'acc': [], 'loss': [], 'f1': [], 'precision': [], 'recall': []},\n",
    "      'val': {'acc': [], 'loss': [], 'f1': [], 'precision': [], 'recall': []},\n",
    "      'test': {'acc': [], 'loss': [], 'f1': [], 'precision': [], 'recall': []}\n",
    "    }\n",
    "\n",
    "    early_stopper = EarlyStopper(patience=3, min_delta=5)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "    dev_dataloader = DataLoader(dev_dataset, batch_size = batch_size, shuffle = True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "      print('########### EPOCH: ' + str(epoch)) \n",
    "      \n",
    "      # track metrics. reset with every new epoch\n",
    "      total_acc = 0\n",
    "      total_f1 = 0\n",
    "      total_precision = 0\n",
    "      total_recall = 0\n",
    "\n",
    "      total_loss_train = 0\n",
    "\n",
    "      # Enter training mode\n",
    "      self.train()\n",
    "\n",
    "      for train_data, train_label in tqdm(train_dataloader):\n",
    "\n",
    "        train_label = train_label.to(device)\n",
    "\n",
    "        # extract input IDs and attention masks to feed to the model\n",
    "        mask = train_data['attention_mask'].squeeze(1).to(device)\n",
    "        input_id = train_data['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "        # set the gradients of all params to zero before using stochastic gradient descent.\n",
    "        # prevents gradients from previous batches from accumulating\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # extract loss and logits to measure performance. flatten lists to 1D\n",
    "        output = self(input_id, mask, train_label)\n",
    "        loss, logits = output.loss, output.logits\n",
    "        predictions = logits.argmax(dim= -1).flatten() \n",
    "        train_label = train_label.flatten()\n",
    "\n",
    "        # NumPy doesn't utilize the GPU. Convert everything to CPU to use sklearn.metrics methods\n",
    "        predictions = predictions[train_label != -100].data.cpu().numpy()\n",
    "        train_label = train_label[train_label != -100].data.cpu().numpy()\n",
    "\n",
    "        # calculate metrics\n",
    "        acc = accuracy_score(train_label, predictions)\n",
    "        f1 = f1_score(train_label, predictions, average=\"macro\")\n",
    "        precision = precision_score(train_label, predictions, average=\"macro\")\n",
    "        recall = recall_score(train_label, predictions, average=\"macro\")\n",
    "\n",
    "        total_acc += acc\n",
    "        total_f1 += f1\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "        total_loss_train += loss.item()\n",
    "\n",
    "        # perform backpropagation to compute loss gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters based on what was calculated during backpropagation\n",
    "        optimizer.step()\n",
    "\n",
    "      print(\"TRAIN\")\n",
    "      print('loss: ' + str(total_loss_train))\n",
    "      print(f\"LOSS: {total_loss_train / len(train_dataset)}\")\n",
    "      print(f\"Acc: {round(total_acc / len(train_dataloader), 2)} | F1: {round(total_f1 / len(train_dataloader), 2)} | Precision: {round(total_precision / len(train_dataloader), 2)} | Recall: {round(total_recall / len(train_dataloader), 2)}\")\n",
    "\n",
    "\n",
    "      self.results['train']['acc'].append(round(total_acc / len(train_dataloader), 2))\n",
    "      self.results['train']['precision'].append(round(total_precision / len(train_dataloader),2))\n",
    "      self.results['train']['recall'].append(round(total_recall / len(train_dataloader), 2))\n",
    "      self.results['train']['f1'].append(round(total_f1 / len(train_dataloader), 2))\n",
    "      self.results['train']['loss'].append(total_loss_train / len(train_dataset))\n",
    "      \n",
    "      # enter evaluation mode: disable dropout and batch normalization to prevent overfitting          \n",
    "      self.eval()\n",
    "\n",
    "      total_acc = 0\n",
    "      total_f1 = 0\n",
    "      total_precision = 0\n",
    "      total_recall = 0\n",
    "\n",
    "      total_loss_dev = 0\n",
    "      \n",
    "      with torch.no_grad():\n",
    "        for dev_data, dev_label in dev_dataloader:\n",
    "\n",
    "          dev_label = dev_label.to(device)\n",
    "\n",
    "          mask = dev_data['attention_mask'].squeeze(1).to(device)\n",
    "          input_id = dev_data['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "          output = self(input_id, mask, dev_label)\n",
    "          loss, logits = output.loss, output.logits\n",
    "\n",
    "          predictions = logits.argmax(dim= -1).flatten() \n",
    "          dev_label = dev_label.flatten()\n",
    "          predictions = predictions[dev_label != -100].data.cpu().numpy()\n",
    "          dev_label = dev_label[dev_label != -100].data.cpu().numpy()    \n",
    "\n",
    "          acc = accuracy_score(dev_label, predictions)\n",
    "          f1 = f1_score(dev_label, predictions, average=\"macro\")\n",
    "          precision = precision_score(dev_label, predictions, average=\"macro\")\n",
    "          recall = recall_score(dev_label, predictions, average=\"macro\")\n",
    "\n",
    "          total_acc += acc\n",
    "          total_f1 += f1\n",
    "          total_precision += precision\n",
    "          total_recall += recall\n",
    "\n",
    "          total_loss_dev += loss.item()\n",
    "\n",
    "      print(\"VALIDATION\")\n",
    "      print(f\"LOSS: {total_loss_dev / len(dev_dataset)}\")\n",
    "      print(f\"Acc: {round(total_acc / len(dev_dataloader), 2)} | F1: {round(total_f1 / len(dev_dataloader), 2)} | Precision: {round(total_precision / len(dev_dataloader), 2)} | Recall: {round(total_recall / len(dev_dataloader), 2)}\")\n",
    "\n",
    "      self.results['val']['acc'].append(round(total_acc / len(dev_dataloader), 2))\n",
    "      self.results['val']['precision'].append(round(total_precision / len(dev_dataloader), 2))\n",
    "      self.results['val']['recall'].append(round(total_recall / len(dev_dataloader), 2))\n",
    "      self.results['val']['f1'].append(round(total_f1 / len(dev_dataloader), 2))\n",
    "      self.results['val']['loss'].append(total_loss_dev / len(dev_dataset))\n",
    "\n",
    "      \n",
    "      if early_stopper.early_stop(total_loss_dev):             \n",
    "          break\n",
    "\n",
    "  # when evaluating a model, you can also use a pre-saved model instead of training from scrach.\n",
    "  # just provide the model as the second argument when calling the evaluate method\n",
    "  def evaluate(self, test_df, model = None):\n",
    "    self.classification_report = None\n",
    "    self.evaluation_score = {\n",
    "        'f1': None,\n",
    "        'acc': None,\n",
    "        'precision': None,\n",
    "        'recall': None,\n",
    "        'loss': None\n",
    "    }\n",
    "\n",
    "    all_true = []\n",
    "    all_predicted = []\n",
    "\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "\n",
    "    total_loss_test = 0\n",
    "\n",
    "    test_dataset = CustomDataset(df_test)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size = 2, shuffle = True)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # decide whether we're evaluating a model we just trained or one that was provided as an arg\n",
    "    if model:\n",
    "      model = model.to(device)\n",
    "    else:\n",
    "      self = self.to(device)\n",
    "\n",
    "    for test_data, test_label in tqdm(test_dataloader):\n",
    "        test_label = test_label.to(device)\n",
    "\n",
    "        mask = test_data['attention_mask'].squeeze(1).to(device)\n",
    "        input_id = test_data['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "        if model:\n",
    "          output = model(input_id, mask, test_label)\n",
    "        else:\n",
    "          output = self(input_id, mask, test_label)\n",
    "\n",
    "        loss, logits = output.loss, output.logits\n",
    "\n",
    "        predictions = logits.argmax(dim=-1).flatten()\n",
    "        test_label = test_label.flatten()\n",
    "\n",
    "        predictions = predictions[test_label != -100].data.cpu().numpy()\n",
    "        test_label = test_label[test_label != -100].data.cpu().numpy()\n",
    "\n",
    "        all_true.extend(test_label)\n",
    "        all_predicted.extend(predictions)\n",
    "\n",
    "        acc = accuracy_score(test_label, predictions)\n",
    "        f1 = f1_score(test_label, predictions, average=\"macro\")\n",
    "        precision = precision_score(test_label, predictions, average=\"macro\")\n",
    "        recall = recall_score(test_label, predictions, average=\"macro\")\n",
    "        \n",
    "        total_acc += acc\n",
    "        total_f1 += f1\n",
    "        total_precision += precision\n",
    "        total_recall += recall\n",
    "\n",
    "        total_loss_test += loss.item()\n",
    "        \n",
    "    print(\"VALIDATION\")\n",
    "    print(f\"LOSS: {total_loss_test / len(test_dataset)}\")\n",
    "    print(f\"Acc: {round(total_acc / len(test_dataloader),3)} | F1: {round(total_f1 / len(test_dataloader), 3)} | Precision: {round(total_precision / len(test_dataloader), 3)} | Recall: {round(total_recall / len(test_dataloader), 3)}\")\n",
    "\n",
    "    self.evaluation_score['f1'] = round(total_f1 / len(test_dataloader), 3)\n",
    "    self.evaluation_score['precision'] = round(total_precision / len(test_dataloader), 3)\n",
    "    self.evaluation_score['recall'] = round(total_recall / len(test_dataloader), 3)\n",
    "    self.evaluation_score['acc']  = round(total_acc / len(test_dataloader),3)\n",
    "    self.evaluation_score['loss'] = total_loss_test / len(test_dataset)\n",
    "\n",
    "    self.classification_report = classification_report(all_true, all_predicted, output_dict=True)\n",
    "\n",
    "  def predict_single(self, sentence, model = None):\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()   \n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "    text = tokenizer(sentence , padding = \"max_length\" , truncation = True, return_tensors = \"pt\" )\n",
    "\n",
    "    label_all_tokens = False\n",
    "    word_ids = text.word_ids()\n",
    "    pwid = None\n",
    "    label_ids = []\n",
    "\n",
    "    for id in word_ids:\n",
    "        if id is None:\n",
    "            label_ids.append(-100)\n",
    "        elif id != pwid:\n",
    "            try:\n",
    "                label_ids.append(labels_to_ids[labels[id]])\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        else:\n",
    "            try:\n",
    "                label_ids.append(labels_to_ids[labels[id]] if label_all_tokens else -100)\n",
    "            except:\n",
    "                label_ids.append(-100)\n",
    "        pwid = id\n",
    "\n",
    "\n",
    "    mask = text['attention_mask'].to(device)\n",
    "    input_id = text['input_ids'].to(device)\n",
    "    label_ids = torch.Tensor(label_ids).unsqueeze(0).to(device)\n",
    "\n",
    "    if model:\n",
    "      logits = model(input_id, mask, None)\n",
    "    else:\n",
    "      logits = self(input_id, mask, None)\n",
    "\n",
    "    logits_clean = logits[0][label_ids != -100]\n",
    "    \n",
    "    predictions = logits_clean.argmax(dim=1).tolist()\n",
    "    prediction_label = [ids_to_labels[i] for i in predictions]\n",
    "    print(tokenizer.tokenize(sentence))\n",
    "    return prediction_label"
   ],
   "metadata": {
    "id": "NvLu__-eYWkX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# class to stop training early if it is showing overfitting tendency\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ],
   "metadata": {
    "id": "RBmx6OUPYhX2",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# convert tags to labels\n",
    "\n",
    "def tags_to_labels(tags, labels_to_ids):\n",
    "  tag_indices = []\n",
    "  for tag in tags.split():\n",
    "      if tag in labels_to_ids:\n",
    "          tag_indices.append(labels_to_ids[tag])\n",
    "      else:\n",
    "          tag_indices.append(o_label)\n",
    "\n",
    "  return tag_indices"
   ],
   "metadata": {
    "id": "1nMQYxRRYitC",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 'O' denotes a token that is not a named-entity defined in our list\n",
    "o_label = labels_to_ids[\"O\"]\n",
    "\n",
    "for df in [df_train, df_val, df_test]:\n",
    "  df[\"labels\"] = df[\"tags\"].apply(lambda tags: tags_to_labels(tags, labels_to_ids))\n"
   ],
   "metadata": {
    "id": "AREe1PHBYpJG",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training & evaluating the model\n",
    "\n",
    "\n",
    "*   model.fit(train_df, val_df, optimizer, batch_size, epochs) -- train the model\n",
    "*   model.results -- get training metrics\n",
    "*   model.evaluate(test_df, model) -- evaluate the model using test data. 'model' arg is optional\n",
    "*   model.evaluation_score -- get F1, precision, accuraccy, and loss\n",
    "*   model.classification_report -- get all metrics for individual named entities\n",
    "*   model.predict_single(sentence, model) -- provide a non-tokenized sentence and get back labels for each word\n",
    "\n"
   ],
   "metadata": {
    "id": "9OwljzEx6twv",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# instantiate the class\n",
    "model = Bert(len(label_list))\n",
    "\n",
    "# use GPU if available, otherwise use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "train_dataset = CustomDataset(df_train)\n",
    "val_dataset = CustomDataset(df_val)\n",
    "\n",
    "# define parameters for training\n",
    "lr = 1e-2\n",
    "momentum = 0.9\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "optimizer = SGD(model.parameters(), lr=lr, momentum=momentum)  \n",
    "\n",
    "# train the model\n",
    "model.fit(train_dataset, val_dataset, optimizer, batch_size, epochs)\n",
    "\n",
    "# save the model for later use\n",
    "torch.save(model, '../../saved_models/BERT/model_final.pth')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BMmKz2qmYucr",
    "outputId": "c1e06539-03c3-4a5c-f533-e4de1f97c114",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "########### EPOCH: 0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 275/275 [06:18<00:00,  1.38s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN\n",
      "loss: 235.30771017074585\n",
      "LOSS: 0.026751672370480428\n",
      "Acc: 0.8 | F1: 0.13 | Precision: 0.16 | Recall: 0.13\n",
      "VALIDATION\n",
      "LOSS: 0.018247363362978025\n",
      "Acc: 0.83 | F1: 0.22 | Precision: 0.29 | Recall: 0.21\n",
      "########### EPOCH: 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 275/275 [06:18<00:00,  1.38s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN\n",
      "loss: 146.48887345194817\n",
      "LOSS: 0.016654032907224666\n",
      "Acc: 0.84 | F1: 0.3 | Precision: 0.39 | Recall: 0.29\n",
      "VALIDATION\n",
      "LOSS: 0.015470505804297815\n",
      "Acc: 0.84 | F1: 0.39 | Precision: 0.47 | Recall: 0.4\n",
      "########### EPOCH: 2\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 275/275 [06:19<00:00,  1.38s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN\n",
      "loss: 118.5966997295618\n",
      "LOSS: 0.013483026344879696\n",
      "Acc: 0.86 | F1: 0.42 | Precision: 0.53 | Recall: 0.4\n",
      "VALIDATION\n",
      "LOSS: 0.013106445241050322\n",
      "Acc: 0.86 | F1: 0.47 | Precision: 0.54 | Recall: 0.47\n",
      "########### EPOCH: 3\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 275/275 [06:19<00:00,  1.38s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN\n",
      "loss: 100.99392771720886\n",
      "LOSS: 0.011481801695908239\n",
      "Acc: 0.88 | F1: 0.49 | Precision: 0.6 | Recall: 0.47\n",
      "VALIDATION\n",
      "LOSS: 0.012595540979007202\n",
      "Acc: 0.87 | F1: 0.52 | Precision: 0.61 | Recall: 0.5\n",
      "########### EPOCH: 4\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 275/275 [06:18<00:00,  1.38s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN\n",
      "loss: 88.65078289806843\n",
      "LOSS: 0.010078533753759484\n",
      "Acc: 0.89 | F1: 0.55 | Precision: 0.65 | Recall: 0.53\n",
      "VALIDATION\n",
      "LOSS: 0.011454672332837833\n",
      "Acc: 0.88 | F1: 0.55 | Precision: 0.63 | Recall: 0.53\n",
      "########### EPOCH: 5\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 275/275 [06:18<00:00,  1.38s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN\n",
      "loss: 79.55221700668335\n",
      "LOSS: 0.009044135630591558\n",
      "Acc: 0.9 | F1: 0.6 | Precision: 0.69 | Recall: 0.58\n",
      "VALIDATION\n",
      "LOSS: 0.010640192907362865\n",
      "Acc: 0.88 | F1: 0.6 | Precision: 0.66 | Recall: 0.6\n",
      "########### EPOCH: 6\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 275/275 [06:18<00:00,  1.38s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN\n",
      "loss: 72.44942620396614\n",
      "LOSS: 0.008236633265571412\n",
      "Acc: 0.91 | F1: 0.63 | Precision: 0.71 | Recall: 0.61\n",
      "VALIDATION\n",
      "LOSS: 0.011035778065495407\n",
      "Acc: 0.89 | F1: 0.6 | Precision: 0.67 | Recall: 0.58\n",
      "########### EPOCH: 7\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 275/275 [06:19<00:00,  1.38s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN\n",
      "loss: 67.31039176136255\n",
      "LOSS: 0.007652386512205838\n",
      "Acc: 0.91 | F1: 0.66 | Precision: 0.73 | Recall: 0.64\n",
      "VALIDATION\n",
      "LOSS: 0.010711795195984591\n",
      "Acc: 0.88 | F1: 0.61 | Precision: 0.64 | Recall: 0.64\n",
      "########### EPOCH: 8\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 275/275 [06:19<00:00,  1.38s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN\n",
      "loss: 63.99589063227177\n",
      "LOSS: 0.007275567375201429\n",
      "Acc: 0.92 | F1: 0.68 | Precision: 0.75 | Recall: 0.66\n",
      "VALIDATION\n",
      "LOSS: 0.010295667174378543\n",
      "Acc: 0.89 | F1: 0.62 | Precision: 0.68 | Recall: 0.62\n",
      "########### EPOCH: 9\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 275/275 [06:19<00:00,  1.38s/it]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TRAIN\n",
      "loss: 58.37360428273678\n",
      "LOSS: 0.006636380659701771\n",
      "Acc: 0.92 | F1: 0.7 | Precision: 0.76 | Recall: 0.68\n",
      "VALIDATION\n",
      "LOSS: 0.010967901358554558\n",
      "Acc: 0.89 | F1: 0.62 | Precision: 0.69 | Recall: 0.61\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = torch.load('../../saved_models/BERT/model_final.pth')"
   ],
   "metadata": {
    "id": "FfX95L9OqPf1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training scores (Accuracy, Loss, F1, Prediction and Recall)"
   ],
   "metadata": {
    "id": "vnquLiis2jx8",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print('Training results per epoch')\n",
    "pd.DataFrame(model.results['train']).transpose()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "XUYIJ7ms1nIS",
    "outputId": "fd7e049a-0d9e-4fb4-a6c3-bbbd11a4ff90",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training results per epoch\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  0         1         2         3         4         5  \\\n",
       "acc        0.800000  0.840000  0.860000  0.880000  0.890000  0.900000   \n",
       "loss       0.026752  0.016654  0.013483  0.011482  0.010079  0.009044   \n",
       "f1         0.130000  0.300000  0.420000  0.490000  0.550000  0.600000   \n",
       "precision  0.160000  0.390000  0.530000  0.600000  0.650000  0.690000   \n",
       "recall     0.130000  0.290000  0.400000  0.470000  0.530000  0.580000   \n",
       "\n",
       "                  6         7         8         9  \n",
       "acc        0.910000  0.910000  0.920000  0.920000  \n",
       "loss       0.008237  0.007652  0.007276  0.006636  \n",
       "f1         0.630000  0.660000  0.680000  0.700000  \n",
       "precision  0.710000  0.730000  0.750000  0.760000  \n",
       "recall     0.610000  0.640000  0.660000  0.680000  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-e9b99f94-40dc-49b4-94ed-fb3eec48242f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>0.026752</td>\n",
       "      <td>0.016654</td>\n",
       "      <td>0.013483</td>\n",
       "      <td>0.011482</td>\n",
       "      <td>0.010079</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.008237</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.007276</td>\n",
       "      <td>0.006636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.680000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9b99f94-40dc-49b4-94ed-fb3eec48242f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e9b99f94-40dc-49b4-94ed-fb3eec48242f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e9b99f94-40dc-49b4-94ed-fb3eec48242f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 66
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Validation scores (Accuracy, Loss, F1, Prediction and Recall)"
   ],
   "metadata": {
    "id": "GD9V_DYF2rER",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print('Validation results per epoch')\n",
    "pd.DataFrame(model.results['val']).transpose()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "g9H0lX7b17Hr",
    "outputId": "28d9bf03-a616-42bb-d4ac-f8635dfaf80c",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Validation results per epoch\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  0         1         2         3         4        5  \\\n",
       "acc        0.830000  0.840000  0.860000  0.870000  0.880000  0.88000   \n",
       "loss       0.018247  0.015471  0.013106  0.012596  0.011455  0.01064   \n",
       "f1         0.220000  0.390000  0.470000  0.520000  0.550000  0.60000   \n",
       "precision  0.290000  0.470000  0.540000  0.610000  0.630000  0.66000   \n",
       "recall     0.210000  0.400000  0.470000  0.500000  0.530000  0.60000   \n",
       "\n",
       "                  6         7         8         9  \n",
       "acc        0.890000  0.880000  0.890000  0.890000  \n",
       "loss       0.011036  0.010712  0.010296  0.010968  \n",
       "f1         0.600000  0.610000  0.620000  0.620000  \n",
       "precision  0.670000  0.640000  0.680000  0.690000  \n",
       "recall     0.580000  0.640000  0.620000  0.610000  "
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-bcce62e7-397f-442c-8ed9-16e0d45413cb\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.88000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.890000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>0.018247</td>\n",
       "      <td>0.015471</td>\n",
       "      <td>0.013106</td>\n",
       "      <td>0.012596</td>\n",
       "      <td>0.011455</td>\n",
       "      <td>0.01064</td>\n",
       "      <td>0.011036</td>\n",
       "      <td>0.010712</td>\n",
       "      <td>0.010296</td>\n",
       "      <td>0.010968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.390000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.66000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.60000</td>\n",
       "      <td>0.580000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.610000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcce62e7-397f-442c-8ed9-16e0d45413cb')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bcce62e7-397f-442c-8ed9-16e0d45413cb button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bcce62e7-397f-442c-8ed9-16e0d45413cb');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing scores"
   ],
   "metadata": {
    "id": "7T440IZs2wvz",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "test_dataset = CustomDataset(df_test)\n",
    "\n",
    "model.evaluate(test_dataset, model)"
   ],
   "metadata": {
    "id": "OJh5wrbG2frb",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pd.DataFrame(model.evaluation_score,index=['score'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "mx_IP7R02zkR",
    "outputId": "b6c3b411-14d3-490a-c1c3-2544b8a02086",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "          f1   acc  precision  recall      loss\n",
       "score  0.669  0.91      0.686   0.677  0.152539"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-5d5c3685-ad03-469d-89e4-24399a27fb5a\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>acc</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.669</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.152539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d5c3685-ad03-469d-89e4-24399a27fb5a')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-5d5c3685-ad03-469d-89e4-24399a27fb5a button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-5d5c3685-ad03-469d-89e4-24399a27fb5a');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Classification report"
   ],
   "metadata": {
    "id": "5ERAvHiT5IaQ",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "creport = pd.DataFrame(model.classification_report).transpose().reset_index()\n",
    "creport['index'][:29] = creport['index'][:29].apply(lambda x: ids_to_labels[int(x)])\n",
    "creport"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 959
    },
    "id": "LRzmhRVl3fS_",
    "outputId": "21c31fa8-90d2-45bb-a0dd-d35df104b624",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             class  precision  recall  f1-score  support\n",
       "0    B-CASE_NUMBER       0.55    0.50      0.53      145\n",
       "1          B-COURT       0.79    0.66      0.72      314\n",
       "2           B-DATE       0.78    0.67      0.72      212\n",
       "3            B-GPE       0.49    0.27      0.35      189\n",
       "4          B-JUDGE       0.53    0.37      0.43      133\n",
       "5         B-LAWYER       0.00    0.00      0.00      512\n",
       "6            B-ORG       0.62    0.48      0.54      189\n",
       "7   B-OTHER_PERSON       0.80    0.63      0.70      410\n",
       "8     B-PETITIONER       0.46    0.21      0.29      237\n",
       "9      B-PRECEDENT       0.78    0.63      0.70      265\n",
       "10     B-PROVISION       0.79    0.72      0.75      260\n",
       "11    B-RESPONDENT       0.48    0.05      0.08      333\n",
       "12       B-STATUTE       0.79    0.55      0.65      214\n",
       "13       B-WITNESS       0.67    0.72      0.69       81\n",
       "14   I-CASE_NUMBER       0.74    0.88      0.81     1138\n",
       "15         I-COURT       0.91    0.77      0.83     1479\n",
       "16          I-DATE       0.89    0.89      0.89      781\n",
       "17           I-GPE       0.45    0.55      0.50      245\n",
       "18         I-JUDGE       0.83    0.62      0.71      577\n",
       "19        I-LAWYER       0.48    0.25      0.33     2159\n",
       "20           I-ORG       0.61    0.58      0.59      520\n",
       "21  I-OTHER_PERSON       0.75    0.69      0.72      910\n",
       "22    I-PETITIONER       0.74    0.42      0.53     1194\n",
       "23     I-PRECEDENT       0.92    0.87      0.89     3871\n",
       "24     I-PROVISION       0.86    0.91      0.88      926\n",
       "25    I-RESPONDENT       0.61    0.33      0.43     1858\n",
       "26       I-STATUTE       0.84    0.84      0.84      522\n",
       "27       I-WITNESS       0.74    0.85      0.79      235\n",
       "28               O       0.90    0.97      0.93    58841"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-286f6695-b301-4a64-9627-8d5b50a7b6f3\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B-CASE_NUMBER</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B-COURT</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.72</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B-DATE</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B-GPE</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B-JUDGE</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.43</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B-LAWYER</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.54</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B-OTHER_PERSON</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.70</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B-PETITIONER</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B-PRECEDENT</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.70</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B-PROVISION</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.75</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B-RESPONDENT</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B-STATUTE</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.65</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B-WITNESS</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I-CASE_NUMBER</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I-COURT</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I-DATE</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I-GPE</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.50</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>I-JUDGE</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.71</td>\n",
       "      <td>577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I-LAWYER</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>I-OTHER_PERSON</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.72</td>\n",
       "      <td>910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I-PETITIONER</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I-PRECEDENT</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.89</td>\n",
       "      <td>3871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I-PROVISION</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>I-RESPONDENT</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I-STATUTE</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I-WITNESS</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.79</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>O</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.93</td>\n",
       "      <td>58841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-286f6695-b301-4a64-9627-8d5b50a7b6f3')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-286f6695-b301-4a64-9627-8d5b50a7b6f3 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-286f6695-b301-4a64-9627-8d5b50a7b6f3');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(model.classification_report)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_u1A3djcJ8y_",
    "outputId": "33567206-041b-46c1-dd85-98e30f5e6d24",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.50      0.53       145\n",
      "           1       0.79      0.66      0.72       314\n",
      "           2       0.78      0.67      0.72       212\n",
      "           3       0.49      0.27      0.35       189\n",
      "           4       0.53      0.37      0.43       133\n",
      "           5       0.00      0.00      0.00       512\n",
      "           6       0.62      0.48      0.54       189\n",
      "           7       0.80      0.63      0.70       410\n",
      "           8       0.46      0.21      0.29       237\n",
      "           9       0.78      0.63      0.70       265\n",
      "          10       0.79      0.72      0.75       260\n",
      "          11       0.48      0.05      0.08       333\n",
      "          12       0.79      0.55      0.65       214\n",
      "          13       0.67      0.72      0.69        81\n",
      "          14       0.74      0.88      0.81      1138\n",
      "          15       0.91      0.77      0.83      1479\n",
      "          16       0.89      0.89      0.89       781\n",
      "          17       0.45      0.55      0.50       245\n",
      "          18       0.83      0.62      0.71       577\n",
      "          19       0.48      0.25      0.33      2159\n",
      "          20       0.61      0.58      0.59       520\n",
      "          21       0.75      0.69      0.72       910\n",
      "          22       0.74      0.42      0.53      1194\n",
      "          23       0.92      0.87      0.89      3871\n",
      "          24       0.86      0.91      0.88       926\n",
      "          25       0.61      0.33      0.43      1858\n",
      "          26       0.84      0.84      0.84       522\n",
      "          27       0.74      0.85      0.79       235\n",
      "          28       0.90      0.97      0.93     58841\n",
      "\n",
      "    accuracy                           0.88     78750\n",
      "   macro avg       0.68      0.58      0.62     78750\n",
      "weighted avg       0.86      0.88      0.86     78750\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Predicting a sentence"
   ],
   "metadata": {
    "id": "FLKCj7_y0N77",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "sentence = 'High Court of Dhaka in Mumbai, witness Ichcaki Uttaran'\n",
    "model.predict_single(sentence)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e-BZZkq_xd4l",
    "outputId": "543d5a00-f666-4d17-f96d-c52de435013e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['high', 'court', 'of', 'dhaka', 'in', 'mumbai', ',', 'witness', 'ich', '##ca', '##ki', 'uttar', '##an']\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['B-COURT',\n",
       " 'I-COURT',\n",
       " 'I-COURT',\n",
       " 'I-COURT',\n",
       " 'I-COURT',\n",
       " 'B-GPE',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-WITNESS',\n",
       " 'I-WITNESS']"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ]
  }
 ]
}